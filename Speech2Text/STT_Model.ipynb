{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-11T13:57:19.698308Z",
     "start_time": "2024-05-11T13:57:16.053813Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "from datasets import load_dataset\n",
    "import warnings\n",
    "\n",
    "from torch import optim\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ],
   "id": "46bfa2bd95146855",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-11T13:57:23.891129Z",
     "start_time": "2024-05-11T13:57:19.701303Z"
    }
   },
   "cell_type": "code",
   "source": "datasets_tr = load_dataset(\"covost2\", \"tr_en\", data_dir=\"Datasets/STT_Datasets/tr\")",
   "id": "cd5d535cc3190ca5",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration tr_en-7cf12dd05348fb65\n",
      "Reusing dataset covost2 (C:\\Users\\Huawei\\.cache\\huggingface\\datasets\\covost2\\tr_en-7cf12dd05348fb65\\1.0.0\\bba950aae1ffa5a14b876b7e09c17b44de2c3cf60e7bd5d459640beffc78e35b)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "cf5790c78547404cad5a1a04eb3a740c"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-11T13:57:24.189678Z",
     "start_time": "2024-05-11T13:57:23.893129Z"
    }
   },
   "cell_type": "code",
   "source": "data = datasets_tr[\"train\"][:1]",
   "id": "67ede4d64b2f2856",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-11T13:57:24.204693Z",
     "start_time": "2024-05-11T13:57:24.192689Z"
    }
   },
   "cell_type": "code",
   "source": "data",
   "id": "b7d083ee7386fc74",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'client_id': ['1c4f1371075f6e9870c2523bc68067c9fbf0a8c3862ac1480fe4c2ebfefa3e5f1f94d6c60e0e02b07eda2effdb6515b2a20053476b39bafa8746e25ac784ef67'],\n",
       " 'file': ['D:/ROBOT-V0/chatbot/Speech2Text/Datasets/STT_Datasets/tr/clips/common_voice_tr_18756242.mp3'],\n",
       " 'audio': [{'path': 'D:/ROBOT-V0/chatbot/Speech2Text/Datasets/STT_Datasets/tr/clips/common_voice_tr_18756242.mp3',\n",
       "   'array': array([ 3.9850403e-14, -1.4853513e-16,  1.2445653e-13, ...,\n",
       "          -3.5560884e-08, -8.3746488e-07,  5.5270289e-07], dtype=float32),\n",
       "   'sampling_rate': 16000}],\n",
       " 'sentence': ['Bunda başarı sağlandı gibi de görünüyor.'],\n",
       " 'translation': ['It appears that this has been succeeded.'],\n",
       " 'id': ['common_voice_tr_18756242']}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-11T13:57:26.329767Z",
     "start_time": "2024-05-11T13:57:24.206688Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import librosa\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "def audio_transformer(audio_path):\n",
    "    audio, sr = librosa.load(audio_path, sr=16000)\n",
    "    audio = librosa.util.normalize(audio)\n",
    "    audio = librosa.feature.melspectrogram(audio)\n",
    "    audio = librosa.power_to_db(audio, ref=np.max)\n",
    "    tensor = torch.from_numpy(audio).T\n",
    "    tensor = tensor.unsqueeze(0)\n",
    "    return tensor"
   ],
   "id": "1703cca05ccdbd52",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-11T13:57:26.345753Z",
     "start_time": "2024-05-11T13:57:26.332757Z"
    }
   },
   "cell_type": "code",
   "source": [
    "alphabet = \"abcdefghijklmnopqrstuvwxyz, \"\n",
    "SOS_token = 0\n",
    "EOS_token = 1\n",
    "\n",
    "def label_processing(label):\n",
    "    label = label.lower()\n",
    "    tensor = torch.zeros(len(label))\n",
    "    for i,c in enumerate(label):\n",
    "        try:\n",
    "            index = alphabet.index(c)+2\n",
    "        except:\n",
    "            if c==\".\":\n",
    "                index = EOS_token\n",
    "        finally:\n",
    "            tensor[i] = torch.tensor([index])\n",
    "    return tensor.unsqueeze(0).long()"
   ],
   "id": "6a28dce04f109ed2",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-11T13:57:27.105411Z",
     "start_time": "2024-05-11T13:57:26.348759Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train_x_list,train_y_list=[],[]\n",
    "for path,label in zip(data[\"file\"],data[\"translation\"]):\n",
    "    train_x_list.append(audio_transformer(path))\n",
    "    train_y_list.append(label_processing(label))"
   ],
   "id": "deb80f947fe57737",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-11T13:57:27.121411Z",
     "start_time": "2024-05-11T13:57:27.108401Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ],
   "id": "4c14202938f26836",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-11T13:57:27.290449Z",
     "start_time": "2024-05-11T13:57:27.282434Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size,layer_size, p):\n",
    "        super(Encoder, self).__init__()\n",
    "        \n",
    "        self.drop = nn.Dropout(p)\n",
    "        self.rnn = nn.LSTM(input_size, hidden_size,layer_size, batch_first=True, dropout=p)\n",
    "    def forward(self, x):\n",
    "        output = self.drop(x)\n",
    "        output, hidden = self.rnn(output)\n",
    "        return output, hidden"
   ],
   "id": "82cb0d30e70131c1",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-11T13:57:27.859020Z",
     "start_time": "2024-05-11T13:57:27.852014Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class Attention(nn.Module):\n",
    "    def __init__(self, hidden_size):\n",
    "        super(Attention, self).__init__()\n",
    "        \n",
    "        self.EO = nn.Linear(hidden_size, hidden_size)\n",
    "        self.Hi = nn.Linear(hidden_size*2, hidden_size)\n",
    "        self.Va = nn.Linear(hidden_size, 1)\n",
    "    def forward(self, keys,query):\n",
    "        hidden_state = query[0].permute(1,0,2)\n",
    "        cell_state = query[1].permute(1,0,2)\n",
    "        \n",
    "        hidden_state = torch.cat((hidden_state, cell_state), dim=-1)\n",
    "        scores = self.Va(torch.tanh(self.Hi(hidden_state) + self.EO(keys)))\n",
    "        \n",
    "        weights = F.softmax(scores, dim=1)\n",
    "        context = torch.sum(torch.mul(weights,keys), dim=1).unsqueeze(1)\n",
    "        \n",
    "        return context"
   ],
   "id": "c832b7641be113de",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-11T13:57:29.697947Z",
     "start_time": "2024-05-11T13:57:29.680954Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self,hidden_size,output_size,layer_size,p):\n",
    "        super(Decoder, self).__init__()\n",
    "        \n",
    "        self.drop = nn.Dropout(p)\n",
    "        self.embedding = nn.Embedding(output_size,hidden_size)\n",
    "        self.rnn = nn.LSTM(hidden_size*2, hidden_size,layer_size, batch_first=True, dropout=p)\n",
    "        self.out = nn.Linear(hidden_size, output_size)\n",
    "        \n",
    "        self.attention = Attention(hidden_size)\n",
    "        \n",
    "    def forward(self,decoder_input, decoder_hidden, encoder_output):\n",
    "        output = self.drop(self.embedding(decoder_input))\n",
    "        \n",
    "        context = self.attention(encoder_output, decoder_hidden)\n",
    "        input_rnn = torch.cat((output, context), dim=-1)\n",
    "        \n",
    "        output, hidden = self.rnn(input_rnn,decoder_hidden)\n",
    "        output = self.out(output)\n",
    "        \n",
    "        return output, hidden"
   ],
   "id": "4e320b33c13d38c",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-11T13:57:30.368739Z",
     "start_time": "2024-05-11T13:57:30.343718Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size,layer_size, output_size, p, max_length):\n",
    "        super(Model, self).__init__()\n",
    "        \n",
    "        self.max_length = max_length\n",
    "        self.drop = nn.Dropout(p)\n",
    "        self.encoder = Encoder(input_size, hidden_size,layer_size,p)\n",
    "        self.decoder = Decoder(hidden_size,output_size,layer_size,p)\n",
    "        \n",
    "    def forward(self,x,target=None):\n",
    "        encoder_output,encoder_hidden = self.encoder(x)\n",
    "        \n",
    "        decoder_outputs = []\n",
    "        \n",
    "        decoder_input = torch.empty(x.size(0),1,dtype=torch.long).fill_(SOS_token)\n",
    "        decoder_hidden = encoder_hidden\n",
    "        \n",
    "        if target is not None:\n",
    "            max_length = target.size(1)\n",
    "        else:\n",
    "            max_length = self.max_length\n",
    "        \n",
    "        for i in range(max_length):\n",
    "            decoder_output, decoder_hidden = self.decoder(decoder_input, decoder_hidden, encoder_output)\n",
    "            decoder_outputs.append(decoder_output)\n",
    "            if target is not None:\n",
    "                decoder_input = target[:, i].unsqueeze(1)\n",
    "            else:\n",
    "                topv,topi = decoder_output.topk(1)\n",
    "                decoder_input = topi.squeeze(1).detach()\n",
    "            \n",
    "                if decoder_input == EOS_token:\n",
    "                    break\n",
    "\n",
    "        decoder_outputs = torch.cat(decoder_outputs,1)\n",
    "        decoder_outputs = F.log_softmax(decoder_outputs,dim=1)\n",
    "        return decoder_outputs"
   ],
   "id": "3713d5d0a7d4041e",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-11T14:05:10.131136Z",
     "start_time": "2024-05-11T14:05:10.117115Z"
    }
   },
   "cell_type": "code",
   "source": "model = Model(128,256,1,len(alphabet)+2,0.2,100)",
   "id": "cf02da3ed9ef6755",
   "outputs": [],
   "execution_count": 26
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-11T14:05:27.452362Z",
     "start_time": "2024-05-11T14:05:27.438357Z"
    }
   },
   "cell_type": "code",
   "source": [
    "criterion = nn.NLLLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=4e-5,weight_decay=1e-5)\n",
    "epochs = 1000"
   ],
   "id": "b38ed6cd7fa74180",
   "outputs": [],
   "execution_count": 27
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-11T14:06:00.266361Z",
     "start_time": "2024-05-11T14:05:27.943358Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for e in range(epochs):\n",
    "    for i,(x,y) in enumerate(zip(train_x_list,train_y_list)):\n",
    "        optimizer.zero_grad()\n",
    "        output = model(x,y).squeeze(0)\n",
    "        loss = criterion(output,y.squeeze(0))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        prediction = \"\"\n",
    "        for i in range(len(output)):\n",
    "            value = torch.argmax(output[i])\n",
    "            prediction += alphabet[value-2]\n",
    "        print(loss.item(),prediction)"
   ],
   "id": "bfcbbe7cf5d4c4f6",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.6957714557647705 ykwkc,,cixxkhrtefu ozldzzlt e gyaahpp,p,\n",
      "3.6986641883850098 kkbkc,cbbvvguijmfueezzf igtp  llgghpp,p,\n",
      "3.694556713104248 kkblb,c ixvluvmxgu ehffibl   llltghppnpn\n",
      "3.689216136932373 kkukc,, ,vizudthmhfezooojzl e lraghpp,pn\n",
      "3.6745636463165283 kbbkkl,ecmbluhjhfhiurooixlt   llgdhpp, n\n",
      "3.6721434593200684 bkblb,,ptvzzuiimfaiurdoqrzpep llhhhpp,p,\n",
      "3.6649317741394043 kkkmb,, gvvzuhihth ujzfirdt plllhghpp,p,\n",
      "3.663952589035034 kkkkc,,bbvaluvimahaeazozxltee lrgzhppnn,\n",
      "3.6421966552734375 kbbkc,febxblnffhxuiexzfmyltpp llgzh,e, ,\n",
      "3.648900270462036 bbk,bi,c,vbztviehh huzffzzzne llashpdn ,\n",
      "3.628690004348755 bbbkc,,ppvalu ruauferziillleedfldzhdd, ,\n",
      "3.6158854961395264 kkkyt,ce,sxzuii mhiorwfrrztep lldhhpp,d,\n",
      "3.6188838481903076 kkkkt,ce,milu , xuiezzfxxxye  lyaggppe  \n",
      "3.607414960861206 kkkkcicccsbouvmhhhaorzoixzzeelllnzhpp,d,\n",
      "3.6047871112823486 kkkkb,lebmvzu txshiuufffiytnd lrgzhdp,  \n",
      "3.594050884246826 kk,kc,,pbx lu ihfhvehloixzsee llazhddddn\n",
      "3.5908055305480957 kkkkpppeivbzuejhgha rhvixztee lrj,hdd,d,\n",
      "3.584099531173706 bb wi,, ,s qhatttuaszza xlzeedm jhhdddd,\n",
      "3.573812961578369 bkkkppwp,vbluit,ghashhf xlpen lla,hed,d,\n",
      "3.5866596698760986 ibbtt,,e,vbzuamhhhae zaqxfteddzlzhheend \n",
      "3.5710792541503906 kkkkpp,p,v luaxhhhiuzzhvrzzee lzczhdd dn\n",
      "3.573685884475708 kkkki,pe xxmhaihshah zot zteell dzgddn  \n",
      "3.550287961959839 kbbppp,ets xhaxhthiu lozxzzeedllhhhddddn\n",
      "3.552325487136841 ikkkpplebvtlhaihhhi hho xzzeddllhzhddndn\n",
      "3.547056198120117 kk t,,peps lhathhhafzzfixzjennmlcheddne,\n",
      "3.5378971099853516 ibkkpppepxxlhishthasuhvzxlteenlljgheend \n",
      "3.5353007316589355 kkkttppp,sxlhaihhhah haixz eedllhheendd \n",
      "3.5221831798553467 kk ppppe v lhathhhae horxftendl cxved d \n",
      "3.5143134593963623 kbkkpppetv hhavhhhaa laz zzeecz ccgee d \n",
      "3.5186703205108643 kk kpp,ebvblh thghah zazxzzeenl zhhdd d \n",
      "3.506837844848633 kkkppppepsxzhaihhhau hazrleee m u,gddnd \n",
      "3.4982800483703613 kk pp,,ebsblhathhhas zaz heee m cceeend \n",
      "3.4760231971740723 kk kpppe,s bhathhhas haz zeeedllcceed d \n",
      "3.4901680946350098 ikwwpppeps bhaihhhah haxxleeedl czeed d \n",
      "3.4814395904541016 kkkkpp,ebs lhavhhhashzaz leee llcceednd \n",
      "3.471651792526245 it tpppe,s lhaxhhhas hav heeenmzczeeend \n",
      "3.4531478881835938 ik tpppppv bhaihhhas hav hzeedl cceed d \n",
      "3.4673995971679688 ik wpppe,svbhathhhas har htennlzczeed d \n",
      "3.453761577606201 ikpppppetvrlhaihhhas har veeddlucceed d \n",
      "3.4297397136688232 ik tpppeps lha hhhah hat zeennlucceed d \n",
      "3.4281153678894043 ik ppppeps bhaththas haz zeee g cceeddd \n",
      "3.4244937896728516 ik ppppeps lhathhhis haz leennl ceeed d \n",
      "3.416607618331909 ikpppppdrs lhathhhah hav zzennllcceed d \n",
      "3.423157215118408 iktppppers bha hhhah haz zzeddl ceeed d \n",
      "3.408554792404175 ii ppppe,sxlhathhhah has zzednlxcceeded \n",
      "3.4109930992126465 ikpppppers bhathhha  hat zzeedlucceed d \n",
      "3.400480270385742 ik ppppers bhathhhas zat heeddllcheed d \n",
      "3.3847644329071045 it ppppprs bhathhhas haz zeeddlucceee d \n",
      "3.3931236267089844 ibpppppdrs vhaththas has zeednlucceed d \n",
      "3.370164394378662 ikpppppers bhaihhhas has zeednl cccdd d \n",
      "3.367934465408325 ii ppppeps zhathhhis haz hzeddl ccced d \n",
      "3.3565216064453125 ii ppppers thathhhas has heeddl cceed d \n",
      "3.34871244430542 ii ppppers bharhhhas zas beeddl cceeddd \n",
      "3.338366985321045 iipppppars uhashhhas har beeddluccedd d \n",
      "3.3372085094451904 ii ppppers hhashhhas haz heeenl cceed d \n",
      "3.3211708068847656 iipppppers bhashthas has heeenl cceed d \n",
      "3.32759428024292 it ppppeps zhathhhas har bzendl cceed d \n",
      "3.3202884197235107 iipppppeps tharhhhas hat hzee l cceed d \n",
      "3.298363447189331 ii ppppdps tharhhhas has heednsuceeed d \n",
      "3.286698818206787 it ppppeps uhashhhas has heenns cceed d \n",
      "3.2830348014831543 iipppppeps thathhhas has zeennl cceed d \n",
      "3.2876808643341064 itpppppdrs bhavhthas has teednluccedd d \n",
      "3.273646593093872 itpppppeps thashhhah has beednlucceed d \n",
      "3.264848232269287 iipppppers bharhhhas har heednl cceed d \n",
      "3.2533810138702393 iipppppers bhathhhas has beennl cceed d \n",
      "3.239210605621338 itpppppeps thashhhas has heennlucceed d \n",
      "3.2349343299865723 iipppppaps bhathhhah hat beednl cceed d \n",
      "3.2173538208007812 iipppppers bhashthas has heednlucceed d \n",
      "3.2124314308166504 iipppppars bhashhhas hat beedds cceed d \n",
      "3.2138524055480957 iipppppaps bharhhhas has beeenl cceed d \n",
      "3.200685977935791 itpppppers bhaththas has beeenz ccced d \n",
      "3.1945958137512207 iipppppdrs bhaththas has heennsucceed d \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "\u001B[1;32m<ipython-input-28-2b5aa2a5bbd7>\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m      2\u001B[0m     \u001B[1;32mfor\u001B[0m \u001B[0mi\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mx\u001B[0m\u001B[1;33m,\u001B[0m\u001B[0my\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;32min\u001B[0m \u001B[0menumerate\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mzip\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mtrain_x_list\u001B[0m\u001B[1;33m,\u001B[0m\u001B[0mtrain_y_list\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      3\u001B[0m         \u001B[0moptimizer\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mzero_grad\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m----> 4\u001B[1;33m         \u001B[0moutput\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mmodel\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mx\u001B[0m\u001B[1;33m,\u001B[0m\u001B[0my\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0msqueeze\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;36m0\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m      5\u001B[0m         \u001B[0mloss\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mcriterion\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0moutput\u001B[0m\u001B[1;33m,\u001B[0m\u001B[0my\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0msqueeze\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;36m0\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      6\u001B[0m         \u001B[0mloss\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mbackward\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001B[0m in \u001B[0;36m_call_impl\u001B[1;34m(self, *input, **kwargs)\u001B[0m\n\u001B[0;32m   1100\u001B[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001B[0;32m   1101\u001B[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001B[1;32m-> 1102\u001B[1;33m             \u001B[1;32mreturn\u001B[0m \u001B[0mforward_call\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m*\u001B[0m\u001B[0minput\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   1103\u001B[0m         \u001B[1;31m# Do not call functions when jit is used\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1104\u001B[0m         \u001B[0mfull_backward_hooks\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mnon_full_backward_hooks\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;33m[\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m[\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m<ipython-input-12-2a20c6b66e4e>\u001B[0m in \u001B[0;36mforward\u001B[1;34m(self, x, target)\u001B[0m\n\u001B[0;32m     22\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     23\u001B[0m         \u001B[1;32mfor\u001B[0m \u001B[0mi\u001B[0m \u001B[1;32min\u001B[0m \u001B[0mrange\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mmax_length\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 24\u001B[1;33m             \u001B[0mdecoder_output\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mdecoder_hidden\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mdecoder\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mdecoder_input\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mdecoder_hidden\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mencoder_output\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     25\u001B[0m             \u001B[0mdecoder_outputs\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mappend\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mdecoder_output\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     26\u001B[0m             \u001B[1;32mif\u001B[0m \u001B[0mtarget\u001B[0m \u001B[1;32mis\u001B[0m \u001B[1;32mnot\u001B[0m \u001B[1;32mNone\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001B[0m in \u001B[0;36m_call_impl\u001B[1;34m(self, *input, **kwargs)\u001B[0m\n\u001B[0;32m   1100\u001B[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001B[0;32m   1101\u001B[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001B[1;32m-> 1102\u001B[1;33m             \u001B[1;32mreturn\u001B[0m \u001B[0mforward_call\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m*\u001B[0m\u001B[0minput\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   1103\u001B[0m         \u001B[1;31m# Do not call functions when jit is used\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1104\u001B[0m         \u001B[0mfull_backward_hooks\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mnon_full_backward_hooks\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;33m[\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m[\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m<ipython-input-11-0ba2de736ece>\u001B[0m in \u001B[0;36mforward\u001B[1;34m(self, decoder_input, decoder_hidden, encoder_output)\u001B[0m\n\u001B[0;32m     13\u001B[0m         \u001B[0moutput\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mdrop\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0membedding\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mdecoder_input\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     14\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 15\u001B[1;33m         \u001B[0mcontext\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mattention\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mencoder_output\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mdecoder_hidden\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     16\u001B[0m         \u001B[0minput_rnn\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mtorch\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mcat\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0moutput\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mcontext\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mdim\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;33m-\u001B[0m\u001B[1;36m1\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     17\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001B[0m in \u001B[0;36m_call_impl\u001B[1;34m(self, *input, **kwargs)\u001B[0m\n\u001B[0;32m   1100\u001B[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001B[0;32m   1101\u001B[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001B[1;32m-> 1102\u001B[1;33m             \u001B[1;32mreturn\u001B[0m \u001B[0mforward_call\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m*\u001B[0m\u001B[0minput\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   1103\u001B[0m         \u001B[1;31m# Do not call functions when jit is used\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1104\u001B[0m         \u001B[0mfull_backward_hooks\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mnon_full_backward_hooks\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;33m[\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m[\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m<ipython-input-10-c706b157969a>\u001B[0m in \u001B[0;36mforward\u001B[1;34m(self, keys, query)\u001B[0m\n\u001B[0;32m     11\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     12\u001B[0m         \u001B[0mhidden_state\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mtorch\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mcat\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mhidden_state\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mcell_state\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mdim\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;33m-\u001B[0m\u001B[1;36m1\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 13\u001B[1;33m         \u001B[0mscores\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mVa\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mtorch\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mtanh\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mHi\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mhidden_state\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;33m+\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mEO\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mkeys\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     14\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     15\u001B[0m         \u001B[0mweights\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mF\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0msoftmax\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mscores\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mdim\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;36m1\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001B[0m in \u001B[0;36m_call_impl\u001B[1;34m(self, *input, **kwargs)\u001B[0m\n\u001B[0;32m   1100\u001B[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001B[0;32m   1101\u001B[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001B[1;32m-> 1102\u001B[1;33m             \u001B[1;32mreturn\u001B[0m \u001B[0mforward_call\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m*\u001B[0m\u001B[0minput\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   1103\u001B[0m         \u001B[1;31m# Do not call functions when jit is used\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1104\u001B[0m         \u001B[0mfull_backward_hooks\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mnon_full_backward_hooks\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;33m[\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m[\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\torch\\nn\\modules\\linear.py\u001B[0m in \u001B[0;36mforward\u001B[1;34m(self, input)\u001B[0m\n\u001B[0;32m    101\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    102\u001B[0m     \u001B[1;32mdef\u001B[0m \u001B[0mforward\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0minput\u001B[0m\u001B[1;33m:\u001B[0m \u001B[0mTensor\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;33m->\u001B[0m \u001B[0mTensor\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 103\u001B[1;33m         \u001B[1;32mreturn\u001B[0m \u001B[0mF\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mlinear\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0minput\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mweight\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mbias\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    104\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    105\u001B[0m     \u001B[1;32mdef\u001B[0m \u001B[0mextra_repr\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;33m->\u001B[0m \u001B[0mstr\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\torch\\nn\\functional.py\u001B[0m in \u001B[0;36mlinear\u001B[1;34m(input, weight, bias)\u001B[0m\n\u001B[0;32m   1846\u001B[0m     \u001B[1;32mif\u001B[0m \u001B[0mhas_torch_function_variadic\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0minput\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mweight\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mbias\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1847\u001B[0m         \u001B[1;32mreturn\u001B[0m \u001B[0mhandle_torch_function\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mlinear\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m(\u001B[0m\u001B[0minput\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mweight\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mbias\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0minput\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mweight\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mbias\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mbias\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 1848\u001B[1;33m     \u001B[1;32mreturn\u001B[0m \u001B[0mtorch\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_C\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_nn\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mlinear\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0minput\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mweight\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mbias\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   1849\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1850\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "execution_count": 28
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-11T14:03:37.686924Z",
     "start_time": "2024-05-11T14:03:37.676071Z"
    }
   },
   "cell_type": "code",
   "source": "len(data[\"translation\"][0]) , data[\"translation\"][0]",
   "id": "140a01fd841dc58e",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40, 'It appears that this has been succeeded.')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 22
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-11T14:03:39.772395Z",
     "start_time": "2024-05-11T14:03:39.765403Z"
    }
   },
   "cell_type": "code",
   "source": "train_y_list[0].size(1)",
   "id": "7e1f3874ab17ff81",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 23
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-11T14:03:40.653862Z",
     "start_time": "2024-05-11T14:03:40.561870Z"
    }
   },
   "cell_type": "code",
   "source": [
    "pred = model(train_x_list[0])\n",
    "pred.shape"
   ],
   "id": "97c32e5b9fd807b3",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 40, 30])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 24
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-11T14:03:41.380003Z",
     "start_time": "2024-05-11T14:03:41.366015Z"
    }
   },
   "cell_type": "code",
   "source": "prediction",
   "id": "94c29c0b844a4e51",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'it appears that this has been succeeded '"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 25
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "e6da31fe531b4d5b",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
