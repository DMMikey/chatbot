{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Noise Filter",
   "id": "c8fb5969dc1c6a7c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-03T00:21:12.550201Z",
     "start_time": "2024-05-03T00:21:09.713384Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import librosa\n",
    "import IPython.display as ipd\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch import nn\n",
    "import soundfile as sf\n",
    "warnings.filterwarnings(\"ignore\")"
   ],
   "id": "b3fb2e62d594c86a",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-03T00:21:13.124538Z",
     "start_time": "2024-05-03T00:21:13.013759Z"
    }
   },
   "cell_type": "code",
   "source": "data = pd.read_csv('Datasets/Filter_Datasets/train.csv')[:1]",
   "id": "1c08e9d288ab9fa",
   "outputs": [],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-03T00:21:13.311468Z",
     "start_time": "2024-05-03T00:21:13.302460Z"
    }
   },
   "cell_type": "code",
   "source": "data",
   "id": "fa2db07266797bc8",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                                    combined_path  \\\n",
       "0  Datasets/Filter_Datasets/combined\\p234_001.wav   \n",
       "\n",
       "                                          clean_path  \n",
       "0  Datasets/Filter_Datasets/clean_train\\p234_001.wav  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>combined_path</th>\n",
       "      <th>clean_path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Datasets/Filter_Datasets/combined\\p234_001.wav</td>\n",
       "      <td>Datasets/Filter_Datasets/clean_train\\p234_001.wav</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-03T00:21:14.421177Z",
     "start_time": "2024-05-03T00:21:14.408174Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def audio(audio_path,label_path):\n",
    "    audio, sr_audio = librosa.load(audio_path)\n",
    "    label, sr_label = librosa.load(label_path)\n",
    "    audio = librosa.util.normalize(audio)\n",
    "    label = librosa.util.normalize(label)\n",
    "    audio = librosa.stft(audio)\n",
    "    label = librosa.stft(label)\n",
    "    tenxor_x = torch.from_numpy(audio).T\n",
    "    tenxor_x = tenxor_x.unsqueeze(0)\n",
    "    tenxor_y = torch.from_numpy(label).T\n",
    "    tenxor_y = tenxor_y.unsqueeze(0)\n",
    "    tenxor_x = tenxor_x.float()\n",
    "    tenxor_y = tenxor_y.float()\n",
    "    return tenxor_x, tenxor_y"
   ],
   "id": "c85cfd810f59c1b",
   "outputs": [],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-03T00:21:16.540022Z",
     "start_time": "2024-05-03T00:21:15.373493Z"
    }
   },
   "cell_type": "code",
   "source": [
    "x_list, y_list = [], []\n",
    "for x,y in zip(data[\"combined_path\"], data[\"clean_path\"]):\n",
    "    tenxor_x, tenxor_y = audio(x,y)\n",
    "    x_list.append(tenxor_x)\n",
    "    y_list.append(tenxor_y)"
   ],
   "id": "c453812e1a2beaa7",
   "outputs": [],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-02T16:06:02.121517Z",
     "start_time": "2024-05-02T16:06:02.094530Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class AudioCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(AudioCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 16, kernel_size=(3, 5), padding=(1, 2))  # Zaman ve frekans boyutlarında farklı kernel boyutları\n",
    "        self.pool = nn.MaxPool2d((2, 2))\n",
    "        self.conv2 = nn.Conv2d(16, 32, kernel_size=(3, 5), padding=(1, 2))\n",
    "        self.fc1 = nn.Linear(32 * 32 * 513, 1024)  # Boyutlar katmanlar ve pooling uygulamalarına bağlı olarak hesaplanmalı\n",
    "        self.fc2 = nn.Linear(1024, 1025 * 125)     # Çıkış boyutunu orijinal spektrum boyutlarına uyarlayın\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 32 * 32 * 513)  # Flatten\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        x = x.view(-1, 125, 1025)  # Çıkışı orijinal boyutlara dönüştür\n",
    "        return x\n"
   ],
   "id": "76a952d54ddbbb3f",
   "outputs": [],
   "execution_count": 103
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-02T16:06:07.023399Z",
     "start_time": "2024-05-02T16:06:02.744304Z"
    }
   },
   "cell_type": "code",
   "source": "model = AudioCNN()",
   "id": "6f723b87b7548277",
   "outputs": [],
   "execution_count": 104
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-02T16:06:08.531786Z",
     "start_time": "2024-05-02T16:06:08.504063Z"
    }
   },
   "cell_type": "code",
   "source": [
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001,weight_decay=1e-5)"
   ],
   "id": "d23765c3a8aeab4b",
   "outputs": [],
   "execution_count": 105
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-02T16:06:10.262667Z",
     "start_time": "2024-05-02T16:06:09.347950Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for e in range(1000):\n",
    "    for x,y in zip(x_list,y_list):\n",
    "        optimizer.zero_grad()\n",
    "        out = model(x)\n",
    "        loss = criterion(out,y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    if e % 10 == 0:\n",
    "        print('Epoch:',e,'Loss:',loss.item())"
   ],
   "id": "d1ab6bc3f36a68fa",
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Expected 4-dimensional input for 4-dimensional weight [16, 1, 3, 5], but got 3-dimensional input of size [1, 125, 1025] instead",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "\u001B[1;32m<ipython-input-106-a5e65b664880>\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m      2\u001B[0m     \u001B[1;32mfor\u001B[0m \u001B[0mx\u001B[0m\u001B[1;33m,\u001B[0m\u001B[0my\u001B[0m \u001B[1;32min\u001B[0m \u001B[0mzip\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mx_list\u001B[0m\u001B[1;33m,\u001B[0m\u001B[0my_list\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      3\u001B[0m         \u001B[0moptimizer\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mzero_grad\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m----> 4\u001B[1;33m         \u001B[0mout\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mmodel\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mx\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m      5\u001B[0m         \u001B[0mloss\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mcriterion\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mout\u001B[0m\u001B[1;33m,\u001B[0m\u001B[0my\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      6\u001B[0m         \u001B[0mloss\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mbackward\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001B[0m in \u001B[0;36m_call_impl\u001B[1;34m(self, *input, **kwargs)\u001B[0m\n\u001B[0;32m   1100\u001B[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001B[0;32m   1101\u001B[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001B[1;32m-> 1102\u001B[1;33m             \u001B[1;32mreturn\u001B[0m \u001B[0mforward_call\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m*\u001B[0m\u001B[0minput\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   1103\u001B[0m         \u001B[1;31m# Do not call functions when jit is used\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1104\u001B[0m         \u001B[0mfull_backward_hooks\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mnon_full_backward_hooks\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;33m[\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m[\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m<ipython-input-103-31b2c63f42a1>\u001B[0m in \u001B[0;36mforward\u001B[1;34m(self, x)\u001B[0m\n\u001B[0;32m     13\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     14\u001B[0m     \u001B[1;32mdef\u001B[0m \u001B[0mforward\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mx\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 15\u001B[1;33m         \u001B[0mx\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mpool\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mF\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mrelu\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mconv1\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mx\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     16\u001B[0m         \u001B[0mx\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mpool\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mF\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mrelu\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mconv2\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mx\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     17\u001B[0m         \u001B[0mx\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mx\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mview\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m-\u001B[0m\u001B[1;36m1\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;36m32\u001B[0m \u001B[1;33m*\u001B[0m \u001B[1;36m32\u001B[0m \u001B[1;33m*\u001B[0m \u001B[1;36m513\u001B[0m\u001B[1;33m)\u001B[0m  \u001B[1;31m# Flatten\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001B[0m in \u001B[0;36m_call_impl\u001B[1;34m(self, *input, **kwargs)\u001B[0m\n\u001B[0;32m   1100\u001B[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001B[0;32m   1101\u001B[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001B[1;32m-> 1102\u001B[1;33m             \u001B[1;32mreturn\u001B[0m \u001B[0mforward_call\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m*\u001B[0m\u001B[0minput\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   1103\u001B[0m         \u001B[1;31m# Do not call functions when jit is used\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1104\u001B[0m         \u001B[0mfull_backward_hooks\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mnon_full_backward_hooks\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;33m[\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m[\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\torch\\nn\\modules\\conv.py\u001B[0m in \u001B[0;36mforward\u001B[1;34m(self, input)\u001B[0m\n\u001B[0;32m    444\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    445\u001B[0m     \u001B[1;32mdef\u001B[0m \u001B[0mforward\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0minput\u001B[0m\u001B[1;33m:\u001B[0m \u001B[0mTensor\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;33m->\u001B[0m \u001B[0mTensor\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 446\u001B[1;33m         \u001B[1;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_conv_forward\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0minput\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mweight\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mbias\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    447\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    448\u001B[0m \u001B[1;32mclass\u001B[0m \u001B[0mConv3d\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0m_ConvNd\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\torch\\nn\\modules\\conv.py\u001B[0m in \u001B[0;36m_conv_forward\u001B[1;34m(self, input, weight, bias)\u001B[0m\n\u001B[0;32m    441\u001B[0m                             _pair(0), self.dilation, self.groups)\n\u001B[0;32m    442\u001B[0m         return F.conv2d(input, weight, bias, self.stride,\n\u001B[1;32m--> 443\u001B[1;33m                         self.padding, self.dilation, self.groups)\n\u001B[0m\u001B[0;32m    444\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    445\u001B[0m     \u001B[1;32mdef\u001B[0m \u001B[0mforward\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0minput\u001B[0m\u001B[1;33m:\u001B[0m \u001B[0mTensor\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;33m->\u001B[0m \u001B[0mTensor\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mRuntimeError\u001B[0m: Expected 4-dimensional input for 4-dimensional weight [16, 1, 3, 5], but got 3-dimensional input of size [1, 125, 1025] instead"
     ]
    }
   ],
   "execution_count": 106
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-02T15:59:31.806728Z",
     "start_time": "2024-05-02T15:59:31.755935Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from torchmetrics import SignalNoiseRatio\n",
    "pred = model(x_list[-1])\n",
    "snr = SignalNoiseRatio()\n",
    "print(snr(pred,y_list[-1]))\n",
    "pred = pred.squeeze(0).T\n",
    "pred = pred.detach().numpy()"
   ],
   "id": "83cb7503bc05517e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(13.5518, grad_fn=<SqueezeBackward0>)\n"
     ]
    }
   ],
   "execution_count": 80
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-02T15:59:41.313897Z",
     "start_time": "2024-05-02T15:59:41.227887Z"
    }
   },
   "cell_type": "code",
   "source": [
    "audio,sr = librosa.load(\"Datasets/Filter_Datasets/combined/p234_094.wav\")\n",
    "audio = librosa.util.normalize(audio)\n",
    "audio = np.abs(librosa.stft(audio))\n",
    "tenxor_x = torch.from_numpy(audio).T\n",
    "tenxor_x = tenxor_x.unsqueeze(0)\n",
    "tenxor_x = tenxor_x.float()\n",
    "pred = model(tenxor_x)\n",
    "pred = pred.squeeze(0).T\n",
    "pred = pred.detach().numpy()"
   ],
   "id": "4dbeacb9f95b8cff",
   "outputs": [],
   "execution_count": 83
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-03T00:28:02.741762Z",
     "start_time": "2024-05-03T00:28:02.576222Z"
    }
   },
   "cell_type": "code",
   "source": [
    "audio,sr = librosa.load(\"Datasets/Filter_Datasets/clean_train/p234_094.wav\")\n",
    "sf.write(\"clean.wav\",audio,sr)"
   ],
   "id": "519b19f32e22099c",
   "outputs": [],
   "execution_count": 54
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-02T15:59:42.265266Z",
     "start_time": "2024-05-02T15:59:42.129971Z"
    }
   },
   "cell_type": "code",
   "source": [
    "audio,sr = librosa.load(\"Datasets/Filter_Datasets/combined/p234_094.wav\")\n",
    "sf.write(\"noise.wav\",audio,sr)"
   ],
   "id": "19f6e01a2fd5935b",
   "outputs": [],
   "execution_count": 85
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-02T15:59:57.085718Z",
     "start_time": "2024-05-02T15:59:57.047185Z"
    }
   },
   "cell_type": "code",
   "source": [
    "y = librosa.istft(pred)\n",
    "sf.write(\"prediction.wav\",y,sr)"
   ],
   "id": "2043f1902c20acb3",
   "outputs": [],
   "execution_count": 87
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
